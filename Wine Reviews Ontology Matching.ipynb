{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ontospy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ontodocs.viz.viz_html_single import *\n",
    "import rdflib\n",
    "import pronto\n",
    "import inflection\n",
    "import re\n",
    "import numpy as npTrain\n",
    "from tqdm import *\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import collections\n",
    "import nltk\n",
    "from lxml import etree\n",
    "from lxml.html.clean import Cleaner\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "import pdb\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Add\n",
    "from keras.layers.core import Dropout, Activation, Flatten, Dense\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Читаем онтологию из файла и расширяем ее\n",
    "- Матчим онтологию и датасет\n",
    "- Подготавливаем датасет\n",
    "- Строим модель классификации текста\n",
    "- Сохраняем результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"./wine-reviews/winemag-data-130k-v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"title_array\"] = reviews[\"title\"].apply(lambda x: re.sub(\"[\\(\\)\\.-]\", \"\", x)).str.lower().str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ онтологии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = json.load(open('wine_ontology.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Копируем свойства родителей в каждого ребенка:\n",
    "    - Если есть уровень вложенности - пропускаем\n",
    "    - Для каждого родителя\n",
    "        - Вызываем проп\n",
    "        - Копируем свойства\n",
    "        - Увеличиваем уровень вложенности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_features(instance, instances):\n",
    "#     if not \"level\" in instance.keys():\n",
    "    instance[\"level\"] = 0\n",
    "    parents = []\n",
    "    if 'parent' in instance.keys():\n",
    "        parents = instance['parent']\n",
    "    if type(parents) is not list:\n",
    "        parents = [parents]\n",
    "    for p in parents:\n",
    "        if not (p == \"wine\"):\n",
    "            propagate_features(instances[p], instances)\n",
    "            for k, v in instances[p].items():\n",
    "                if k not in instance.keys():\n",
    "                    instance[k] = instances[p][k]\n",
    "            instance['level'] = max(instance['level'], instances[p]['level'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in instances.items():\n",
    "    propagate_features(v, instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовать признак madeFromGrape (для ускорения обработки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in instances.items():\n",
    "    if 'madeFromGrape' in v.keys():\n",
    "        if type(v['madeFromGrape']) is list:\n",
    "            v['madeFromGrape'] = set(v['madeFromGrape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформировать фичу для дальнейшего матчинга имени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in instances.items():\n",
    "    v['name_array'] = inflection.underscore(k).split(\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сматчить вина из онтологии и вина из отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(x, y):\n",
    "    x = list(set(x))\n",
    "    y = list(set(y))\n",
    "    intersection = list(set([a for a in x if a in y]))\n",
    "    union = list(set(x + y))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_variety(instance, row):\n",
    "    if 'madeFromGrape' not in instance.keys():\n",
    "        return 0\n",
    "    if type(instance[\"madeFromGrape\"]) is list:\n",
    "        return int(row[\"variety\"] in instance[\"madeFromGrape\"]) / len(instance[\"madeFromGrape\"])\n",
    "    else:\n",
    "        return int(row[\"variety\"] == instance[\"madeFromGrape\"])\n",
    "\n",
    "def compare_region(instance, row):\n",
    "    if 'locatedIn' not in instance.keys():\n",
    "        return 0\n",
    "    return int((row[\"region_1\"] == instance[\"locatedIn\"]) or \\\n",
    "            (row[\"region_2\"] == instance[\"locatedIn\"]) or \\\n",
    "            (row[\"country\"] == instance[\"locatedIn\"]) or \\\n",
    "            (row[\"province\"] == instance[\"locatedIn\"]))\n",
    "\n",
    "def compare_maker(instance, row):\n",
    "    if 'hasMaker' not in instance.keys():\n",
    "        return 0\n",
    "    return int(row['winery'] == instance['hasMaker'])\n",
    "\n",
    "def compare_name(instance, row):\n",
    "    return jaccard(instance[\"name_array\"], row[\"title_array\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_from_ontology = []\n",
    "for i in tqdm(reviews.index):\n",
    "    r = reviews.loc[i]\n",
    "    wine_points = []\n",
    "    wines = []\n",
    "    levels = []\n",
    "    for k, v in instances.items():\n",
    "        points = compare_variety(v, r) + compare_region(v, r) + compare_maker(v, r) + compare_name(v, r)\n",
    "        wine_points.append(points)\n",
    "        wines.append(k)\n",
    "        levels.append(v['level'])\n",
    "    \n",
    "    wine_from_ontology.append(wines[np.argmax(wine_points)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"wine_from_ontology\"] = wine_from_ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(\"reviews_with_matching.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Улучшить качество матчинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чистка отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"filtered_description\"] = reviews[\"description\"].str.lower().apply(lambda x: re.sub(\"[^\\w\\s]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"filtered_description\"] = reviews[\"filtered_description\"].str.lower().str.split().apply(lambda x: [w for w in x if w not in stopwords_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"filtered_description\"] = reviews[\"filtered_description\"].apply(lambda x: [w for w in x if len(w) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = nltk.FreqDist([w for r in reviews[\"filtered_description\"] for w in r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_frequency = np.percentile(list(frequencies.values()), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"filtered_description\"] = reviews[\"filtered_description\"].apply(lambda x: [w for w in x if frequencies[w] > low_frequency])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(word_list):\n",
    "    processed_word_list = []\n",
    "    for word in word_list:\n",
    "        word = mystem.lemmatize(word)[0]\n",
    "        processed_word_list.append(word)\n",
    "    return processed_word_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for r in tqdm(reviews[\"filtered_description\"]):\n",
    "    lemmas.append(lemmatize_words(r))\n",
    "reviews[\"filtered_description\"] = lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формирование выборки\n",
    "### (Из подмножества вин)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = reviews[\"filtered_description\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index(w, words):\n",
    "    if w not in words.keys():\n",
    "        words[w] = len(words.keys()) + 1\n",
    "    return words[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(x, feature):\n",
    "    if feature not in instances[x].keys():\n",
    "        return None\n",
    "    if type(instances[x][feature]) is list:\n",
    "        return np.random.choice(instances[x][feature])\n",
    "    return instances[x][feature]\n",
    "    \n",
    "for f in [\"locatedIn\", \"madeFromGrape\", \"hasSugar\", \"hasBody\", \"hasFlavor\", \"hasColor\"]:\n",
    "    reviews[f + \"_feature\"] = reviews[\"wine_from_ontology\"].apply(lambda x: extract_feature(x, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"color\"] = reviews[\"hasColor_feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(\"reviews_with_wine_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"color\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(reviews, columns=[\"color\"])[[\"color_Red\", \"color_White\", \"color_Rose\"]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбрать случайным образом стартовые узлы онтологии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.5\n",
    "all_wines = reviews[\"wine_from_ontology\"].unique()\n",
    "train_wines = np.random.choice(reviews[\"wine_from_ontology\"].unique(), size=int(all_wines.shape[0] * ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = reviews[reviews[\"wine_from_ontology\"].apply(lambda x: x in train_wines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = reviews.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "X_train = [[get_word_index(w, words) for w in text] for text in tqdm(train[\"filtered_description\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [[get_word_index(w, words) for w in text] for text in tqdm(test[\"filtered_description\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y[test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[train.index][\"train\"] = True\n",
    "reviews[test.index][\"train\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация логистической регрессией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO имплементировать логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация моделью Yoon Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 20000  # vocabulary size\n",
    "maxlen = 100  # maximum length of the review\n",
    "batch_size = 32\n",
    "embedding_dims = 20\n",
    "ngram_filters = [3, 5, 7]\n",
    "nb_filter = 1200  # number of filters for each ngram_filter\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовать к bag of words каждое предложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "print('Loading data...')\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer =  Input(shape=(maxlen,))\n",
    "embeddings = Embedding(max_features, embedding_dims, input_length=maxlen)(input_layer)\n",
    "dropout = Dropout(0.)(embeddings)\n",
    "outs = []\n",
    "for n_gram in ngram_filters:\n",
    "    convolution = Convolution1D(filters=nb_filter,\n",
    "                                 kernel_size=n_gram,\n",
    "                                 padding='valid',\n",
    "                                 activation='relu',\n",
    "                                 strides=1,\n",
    "                                 input_shape=(embedding_dims, maxlen))(dropout)\n",
    "    pooling = MaxPooling1D(pool_size=maxlen - n_gram + 1)(convolution)\n",
    "    flatten = Flatten()(pooling)\n",
    "    outs.append(flatten)\n",
    "added = Add()(outs) \n",
    "dropout = Dropout(0.)(added)\n",
    "dense = Dense(3, input_dim=nb_filter * len(ngram_filters))(dropout)\n",
    "activation = Activation('sigmoid')(dense)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data=(X_test, y_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('color_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in train_wines:\n",
    "#     wine_reviews = reviews[reviews[\"wine_from_ontology\"] == w][\"filtered_description\"][0:5]\n",
    "#     wine_reviews_texts = [[get_word_index(w) for w in text] for text in wine_reviews]\n",
    "#     wine_reviews_padded_texts = sequence.pad_sequences(wine_reviews_texts, maxlen=maxlen)\n",
    "#     train_wine_colors[w] = [\"Red\", \"White\", \"Rose\"][np.argmax(model.predict(wine_reviews_padded_texts).mean(axis=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in test[\"wine_from_ontology\"].unique():\n",
    "#     wine_reviews = reviews[reviews[\"wine_from_ontology\"] == w][\"filtered_description\"][0:5]\n",
    "#     wine_reviews_texts = [[get_word_index(w) for w in text] for text in wine_reviews]\n",
    "#     wine_reviews_padded_texts = sequence.pad_sequences(wine_reviews_texts, maxlen=maxlen)\n",
    "#     test_wine_colors[w] = [\"Red\", \"White\", \"Rose\"][np.argmax(model.predict(wine_reviews_padded_texts).mean(axis=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_answers = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_answers = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_X = sequence.pad_sequences(X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers = np.array([\"Red\", \"White\", \"Rose\"])[np.argmax(predicted_y, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение восстановленного фрагмента онтологии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[get_word_index(w, words) for w in text] for text in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = sequence.pad_sequences(X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(int(len(X_padded) / batch_size))):\n",
    "    batches.append(model.predict(X_padded[i*batch_size:(i+1)*batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches.append(model.predict(X_padded[len(batches) * batch_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = [x for l in batches for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"guessed_color\"] = np.array([\"Red\", \"White\", \"Rose\"])[np.argmax(predicted_y, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация исходной и восстановленной онтологии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Определить исходный цвет \n",
    "- Определить угаданный цвет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wines = train[\"wine_from_ontology\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wines = test[\"wine_from_ontology\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guessed_color_matching = pd.get_dummies(reviews, columns=[\"guessed_color\"])[[\"wine_from_ontology\", \"guessed_color_Red\", \"guessed_color_White\"]]\n",
    "guessed_color_matching = guessed_color_matching.groupby(\"wine_from_ontology\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_matching = pd.get_dummies(reviews, columns=[\"color\"])[[\"wine_from_ontology\", \"color_Red\", \"color_White\"]]\n",
    "color_matching = color_matching.groupby(\"wine_from_ontology\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = [{\"id\": w, \"type\": \"wine\"} for w in wine]\n",
    "test_nodes = [{\"id\": w, \"type\": \"wine\", \"new\": True} for w in wine]\n",
    "nodes = train_nodes + test_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes += [{\"id\": \"Red\", \"type\": \"feature\"}, {\"id\": \"White\", \"type\": \"feature\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in color_matching.iterrows():\n",
    "    if (r.sum() > 0):\n",
    "        links.append({\n",
    "            \"source\": i,\n",
    "            \"target\": np.argmax(r).replace(\"color_\", \"\"),\n",
    "            \"type\": \"original\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in guessed_color_matching.iterrows():\n",
    "    links.append({\n",
    "        \"source\": i,\n",
    "        \"target\": np.argmax(r).replace(\"guessed_color_\", \"\"),\n",
    "        \"type\": \"guessed\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    \"nodes\": nodes,\n",
    "    \"links\": links\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
